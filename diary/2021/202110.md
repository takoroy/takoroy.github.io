# 2021年10月

## 10月2日

この日記は日々の勉強の記録を残すためであって、断じてお買い物の記録を残すためではない。
その本義を思い出したので、今週読んだ論文について簡単にメモを残してみようと思う。

### 超解像

まず、超解像の手法であるReal-ESRGANとその元となったESRGANの論文を読んだ。

- [Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data](https://arxiv.org/abs/2107.10833)
- [Esrgan: Enhanced super-resolution generative adversarial networks](https://arxiv.org/abs/1809.00219)

自分の論文の読み方として、「とりあえずなんか凄そうな手法の論文を読む→わかんなかったところを個別に潰していく」という順番なので、Real-ESRGANの方を先に読んでいる。

Real-ESRGANの方は、超解像の学習データにどのようにしてノイズを加えて劣化した低解像度画像を作るのか、という部分に腐心している研究である。
![Real-ESRGAN](https://gyazo.com/3c0b9c15d4b345c8945ee723a562d4d0/thumb/1000)

超解像の目的は、低解像度の画像を高解像度にしたい、というものであるが、現実に存在する低解像度の画像というのは、さまざまな条件によって劣化するものである。例えば撮影条件によって劣化したり、インターネット上のサービスを流通する過程で圧縮される。こういった劣化を適切に取り込んだ低解像度画像を作らないと、現実の低解像度画像に超解像手法を適用してもあまり良い結果にならない、というわけである。

Real-ESRGANでは、モデルの学習時に与える低解像度画像に施す劣化のプロセスを見直すことで、「高品質」な劣化画像を作ることに成功している。例えば、画像をJPEG等で圧縮した時に境界線上に生じるような妙に明るい箇所やダブって見えてしまうノイズなどを丁寧に再現しようとしている。
![劣化プロセスの見直し](https://gyazo.com/95dcfedf82719f0a5405ac40dcbcc76d/thumb/1000)

次に、ベースとなっている手法であるESRGANについてみてみよう。

ESRGANは、SRGANという超解像手法を改善するためにネットワークアーキテクチャを見直したり、Perceptual損失の方法を見直したりしている。
ネットワークアーキテクチャで注目するべきは、BatchNormalizationを全面的に取り除いていることである。通常、BNなしでは深いネットワークの訓練は安定しないことが多いが、この研究では、初期値を標準的な初期化のスケールの0.1倍という小さいスケールで行い、さらにResidual部分の重みを徐々に上げるという訓練上の工夫を行うことでその問題を回避している。
![RRDB](https://gyazo.com/cf9b62fd447f88ccf73732dde240bbed/thumb/1000)

Perceptual損失は、通常ImageNetで事前学習したVGGの特徴マップを用いて計算されるが、本手法では、特徴マップのActivation前の特徴マップを使用している。Activation(ここではReLU)を適用してしまうと、いうまでもなく特徴マップはスパースになってしまう。そのため、訓練が非効率になってしまうという問題が生じていた、ということを突き止めている。また、興味深いのは、事前学習に使用するデータセットは、マテリアル認識のためのものが良い結果になったということであった。超解像は、映っている物体の質感を復元するという要素を含んでいる。そのため、マテリアル認識系のデータセットで事前学習済みのVGGを使用するというのは理にかなっているように思う。

また、初めて知ったのだが、GANの訓練方法として、Relativistic GANという方法を採用している。通常のGANではDiscriminatorは生成された画像の真偽を判定できるように訓練される。しかし、Relativistic GANでは、与えられた2つの画像のどちらがより本物らしいか、ということを判定できるように訓練される。直感的には、Relativistic GANでは、質の悪いGeneratorとDiscriminatorがぐるぐると同じ場所を追いかけっこするような振動的な振る舞いを抑制してくれるような気がするが、詳細は今後元論文を読んでみて明らかにしたいと思う。

### 物体検出

次に、特に回転物体に対する検出手法の論文を読んだ。

- [DAFNe: A One-Stage Anchor-Free Deep Model for Oriented Object Detection](https://arxiv.org/abs/2109.06148)

加えて、ベースとなっている手法であるFCOSの論文も読んだ。ぼんやりとどういう手法なのかは理解していたつもりだったが、改めて論文を読むのも大切である。

- [Fcos: Fully convolutional one-stage object detection](https://arxiv.org/abs/1904.01355)

先にFCOSについて確認してみよう。

FCOSは、アンカーフリーな物体検出手法の代表的な手法である。アンカーにまつわる様々なハイパーパラメータの困難を回避し、高い精度の物体検出を実現している。

FCOSは以下のような構造をしている。バックボーンのネットワークの各段階の特徴マップを元にFeature Pyramidを構築し、さまざまなスケールの物体を効率的に検出できるようにしている。ヘッド部分は大きく2つに分かれており、1つは分類とCenter-nessを予測するブランチ、もう1つは特徴マップのセルからの矩形位置を予測するためのブランチである。
![FCOの構造](https://gyazo.com/e607987cc2d89e13b1added4b86c5562/thumb/1000)

まず、FCOSにおける矩形位置の表現方法を確認しよう。下図の左側がそうであるが、オレンジの点（特徴マップ上のセルの中心を表す）が、矩形の左右上下の辺からどれだけ離れているかを$l,r,t,b$で表している。これを予測できれば、矩形を復元するのは容易である。この$l,r,t,b$の大きさは物体の大きさと密接な関係があるので、Featrue Pyramidのどこに対応させるかをこれらの値の最大値によって決めている。
![FCOS矩形](https://gyazo.com/a8abba85aa1fff61507254ff9440803f/thumb/1000)

次に、Center-nessについて確認しよう。Center-nessは本研究で提案された手法で、質の悪い検出を一掃できる。Center-nessは、下式によって与えられる。

$$
\text { centerness }^{*}=\sqrt{\frac{\min \left(l^{*}, r^{*}\right)}{\max \left(l^{*}, r^{*}\right)} \times \frac{\min \left(t^{*}, b^{*}\right)}{\max \left(t^{*}, b^{*}\right)}}
$$

図で見た方がわかりやすいが、物体矩形の中心ほど大きく、周辺にいくほど小さいという値である。FCOSでは、このCenter-nessをも訓練の対象にしている。

![center-ness](https://gyazo.com/8f2276f09e5069a17c91e022ea617ed9/thumb/1000)

クラス分類のスコアは高いが真の物体領域とのIoUが小さいという、質の悪い検出結果（必ずしも誤検出とは限らないが、後処理のネックとなる検出も含む）があったとしても、Center-nessが推定できていれば、これらを除外することができる。下図は様々な検出と真の物体矩形とのIoUおよび分類スコアの散布図であるが、ここにcenter-nessを掛けるだけで、質の悪い検出結果（散布図の右下）は散布図の左下へと押し込まれる。
![center-ness_vs_IoU](https://gyazo.com/ca1ef166becf88aa8785a774430194ce/thumb/1000)

つづけて、回転物体検出手法であるDAFNeをみてみよう。ネットワークアーキテクチャはFCOSを踏襲しているが、Center-Nessブランチが、Regressionブランチの方に移動している。また、これらのターゲットは、回転物体に対応するためにカスタマイズされている。

![DAFNe](https://gyazo.com/2e9e97743e1dbcd5f955a218de881183/thumb/1000)

まず、Center-nessについては、回転物体に合わせて以下の図のような変更が加えられている。物体矩形が回転するので、Center-nessも回転させましょうというわかりやすい変更である。

![DAFNe-centerness](https://gyazo.com/0b16d96973410d3a235aaec5d09e534b/thumb/1000)

つづけて、Regressionの方もみてみよう。回転物体検出初心者なので、あまり知らないのだが、直感的には、検出点（下図のオレンジの点）からの四隅へのベクトルを推定するという方法が思いつく（下図(a)）。しかし、この方法以外にも戦略が考えられるので、本研究ではどの戦略が最も良いかを比較している。結論としては、検出点から矩形の中心を推定し、そこから四隅へのベクトルを推定するというCenter-to-Corner戦略が最も安定して良い結果になったそうだ。直感的にだが、一度中央を推定してから四隅を推定するのに必要な情報は、Center-nessの推定に必要な情報と密接な関係にあると思われる。そおのため、FCOSとの差異である、Center-nessとRegressionが同一のブランチに所属するようにしたという変更点は納得感があると思う。

![DAFNe-regression](https://gyazo.com/b3b9df2f9d02d4f0866d1573efa13ec0/thumb/1000)

### これからの論文読解とのつきあいかた

ここ最近、子供が生まれたり、転職したり、マイホームの計画が進行したりとちょっと忙しかったので、論文を読むペースを遅くせざるを得なかった。ようやく落ち着いてきたので、今後どのようにして生活に論文を読む時間を組み込むかを考えみた。

平日の夜（21時以降）は、妻は比較的自由にしてもらい、自分が子供をあやす時間である。この時間帯は、Youtubeなどでマイホームや家具の勉強をしながら、子供をあやすという過ごし方にしていたのだが、主従を逆転させ、子供をあやしながら何かをするという心の余裕ができてきた。そういうわけで、この時間帯にiPadで論文を読むことにした。無論、子供が泣き出したりしたらかまってあげる必要があるが、基本的にはおとなしくしてくれているので、1日1本くらい論文を読むことはできる。

しかし、基本的には「ながら」読みなので、普通に読むよりは知識としての定着が弱い。そういうわけで、2日読んだらその次の日は得た知識を整理する、ということにした。自分は以前から読んだ論文はScrapboxにメモをまとめるようにしており、今でもこれは継続している。iPadでこの作業をするのは厳しいが、Macbook Airを寝室に持ち込んで、子供をあやしながらてきぱきメモをまとめるということは、不可能ではないということが最近わかってきた。

そういうわけで、月火は論文を読み、水に整理、木金は論文を読み、土の午前中に整理する、というリズムが作れそうである。こうすることで、週に4本の論文を読みつつ、土曜日の午後はアウトプットに、日曜日は完全な安息日として確保できるようになったのだ。

土曜日の午後をアウトプットに使えることになったので、この日記のように、読んだ論文を簡単にまとめるということを月イチくらいのペースで行いつつ、実験や実装を行う時間にあてたいと考えている。
